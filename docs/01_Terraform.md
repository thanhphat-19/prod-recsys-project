# **Step 1: Set Active Project**

```python
gcloud config set project <project_name>
```

**What this does:**

- SetsÂ **`<proJec-name>`**Â as yourÂ **default project**Â for allÂ **`gcloud`**Â commands
- All future commands will run against this project unless you specify otherwise

**Why needed:**

- You might have multiple GCP projects
- This ensures Terraform and gcloud commands target the correct projec

**Verify it worked:**

```python
gcloud config get-value project
# Should output: <project_name>
```

# **Step 2: Enable Required APIs**

```bash
gcloud services enable container.googleapis.com
gcloud services enable storage.googleapis.com

```

**What this does:**

- **`container.googleapis.com`**Â - Enables Google Kubernetes Engine (GKE) API
- **`storage.googleapis.com`**Â - Enables Cloud Storage (GCS) API
- **`artifactregistry.googleapis.com`**Â - Enables Artifact Registry API

**Why needed:**

- GCP APIs areÂ **disabled by default**Â for security and cost reasons
- Terraform cannot create resources if the APIs are not enabled
- Each API must be explicitly enabled before use

**What happens:**

```bash
Operation "operations/..." finished successfully.
```

**Behind the scenes:**

- GCP activates these services in your project
- May take 1-2 minutes to propagate
- You'll be billed for usage of these services

**Verify APIs are enabled:**

```bash
gcloud services list --enabled | grep -E "container|storage|artifactregistry"
```

# **Step 3: Initialize Terraform**

```bash
cd terraform
terraform init
```

**What this does:**

1. **Downloads provider plugins**Â - Downloads the Google Cloud provider (~100MB)
2. **Initializes backend**Â - Sets up where Terraform state will be stored (local file)
3. **CreatesÂ `.terraform/`Â directory**Â - Stores provider plugins and modules
4. **CreatesÂ `.terraform.lock.hcl`**Â - Locks provider versions for consistency

**Output you'll see:**

```bash
Initializing the backend...

Initializing provider plugins...
- Finding hashicorp/google versions matching "~> 5.0"...
- Installing hashicorp/google v5.x.x...
- Installed hashicorp/google v5.x.x

Terraform has been successfully initialized!
```

**Files created:**

```bash
terraform/
â”œâ”€â”€ .terraform/           # Provider plugins (gitignored)
â”œâ”€â”€ .terraform.lock.hcl   # Provider version lock
â”œâ”€â”€ main.tf
â”œâ”€â”€ variables.tf
â”œâ”€â”€ outputs.tf
â””â”€â”€ terraform.tfvars
```

**Why needed:**

- Must be run before any other Terraform command
- Downloads necessary tools to interact with GCP
- Only needs to be run once (or when providers change)

# **Step 4: Preview Changes (terraform plan)**

```bash
terraform plan
```

**What this does:**

1. **Reads your configuration**Â - ParsesÂ main.tf,Â variables.tf,Â **`terraform.tfvars`**
2. **Authenticates to GCP**Â - Uses yourÂ **`gcloud`**Â credentials
3. **Queries current state**Â - Checks what resources already exist
4. **Calculates changes**Â - Determines what needs to be created/modified/deleted
5. **Shows you a preview**Â - Displays what will happen (doesn't make changes yet)

**Output you'll see:**

```bash
Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_artifact_registry_repository.docker_repo will be created
  + resource "google_artifact_registry_repository" "docker_repo" {
      + create_time   = (known after apply)
      + description   = "Docker images for recommendation system"
      + format        = "DOCKER"
      + location      = "us-east1"
      + name          = (known after apply)
      + project       = "product-recsys-mlops"
      + repository_id = "product-recsys-mlops-recsys"
    }

  # google_container_cluster.primary will be created
  + resource "google_container_cluster" "primary" {
      + cluster_ipv4_cidr       = (known after apply)
      + enable_autopilot        = true
      + endpoint                = (known after apply)
      + location                = "us-east1"
      + name                    = "product-recsys-mlops-gke"
      + project                 = "product-recsys-mlops"
      + self_link               = (known after apply)
      ...
    }

  # google_storage_bucket.data will be created
  + resource "google_storage_bucket" "data" {
      + force_destroy         = true
      + location              = "US-EAST1"
      + name                  = "product-recsys-mlops-recsys-data"
      + project               = "product-recsys-mlops"
      + self_link             = (known after apply)
      + uniform_bucket_level_access = true
      ...
    }

Plan: 3 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + artifact_registry_url = "us-east1-docker.pkg.dev/product-recsys-mlops/product-recsys-mlops-recsys"
  + configure_kubectl     = "gcloud container clusters get-credentials product-recsys-mlops-gke --region us-east1 --project product-recsys-mlops"
  + gcs_bucket            = "product-recsys-mlops-recsys-data"
  + gcs_bucket_url        = "gs://product-recsys-mlops-recsys-data"
  + project_id            = "product-recsys-mlops"
  + region                = "us-east1"
```

**What the symbols mean:**

- **`+`**Â = Will beÂ **created**
- **`~`**Â = Will beÂ **modified**
- = Will beÂ **destroyed**
- **`/+`**Â = Will beÂ **replaced**Â (destroyed then created)

**Why needed:**

- **Safety check**Â - Review changes before applying
- **Catch errors**Â - Spot mistakes in configuration
- **No cost**Â - Doesn't create anything, just shows plan
- **Best practice**Â - Always runÂ **`plan`**Â beforeÂ **`apply`**

# **Step 5: Create Infrastructure (terraform apply)**

```bash
terraform apply
```

**What this does:**

1. **RunsÂ `terraform plan`Â again**Â - Shows you the changes
2. **Asks for confirmation**Â - You must typeÂ **`yes`**Â to proceed
3. **Creates resources in order**Â - Respects dependencies
4. **Saves state**Â - Records what was created inÂ **`terraform.tfstate`**
5. **Shows outputs**Â - Displays important information

**Interactive prompt:**

```bash
Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes    â† Type 'yes' and press Enter
```

**What happens (in order):**

## **5.1 Create GCS Bucket (30 seconds)**

```bash
google_storage_bucket.data: Creating...
google_storage_bucket.data: Creation complete after 2s [id=product-recsys-mlops-recsys-data]
```

- Creates bucket inÂ **`us-east1`**
- Sets lifecycle rule (delete files after 90 days)
- Enables uniform bucket-level access

## **5.2 Create Artifact Registry (30 seconds)**

```bash
google_artifact_registry_repository.docker_repo: Creating...
google_artifact_registry_repository.docker_repo: Creation complete after 3s
```

- Creates Docker registry inÂ **`us-east1`**
- Ready to receive Docker images

## **5.3 Create GKE Autopilot Cluster (10-15 minutes) â°**

```bash
google_container_cluster.primary: Creating...
google_container_cluster.primary: Still creating... [10s elapsed]
google_container_cluster.primary: Still creating... [20s elapsed]
...
google_container_cluster.primary: Still creating... [10m0s elapsed]
google_container_cluster.primary: Creation complete after 12m34s
```

- Creates Kubernetes control plane
- Configures Autopilot settings
- Sets up networking
- **This is the longest step!**

## **5.4 Save State**

```bash
Apply complete! Resources: 3 added, 0 changed, 0 destroyed.

Outputs:

artifact_registry_url = "us-east1-docker.pkg.dev/product-recsys-mlops/product-recsys-mlops-recsys"
configure_kubectl = "gcloud container clusters get-credentials product-recsys-mlops-gke --region us-east1 --project product-recsys-mlops"
docker_push_example = "docker push us-east1-docker.pkg.dev/product-recsys-mlops/product-recsys-mlops-recsys/recsys-api:latest"
gcs_bucket = "product-recsys-mlops-recsys-data"
gcs_bucket_url = "gs://product-recsys-mlops-recsys-data"
project_id = "product-recsys-mlops"
region = "us-east1"
```

**Files created:**

```bash
terraform/
â”œâ”€â”€ terraform.tfstate      # Current state (what exists in GCP)
â”œâ”€â”€ terraform.tfstate.backup  # Previous state (backup)
```

**Why needed:**

- Actually creates the infrastructure
- Provisions real GCP resources
- Starts billing (resources now cost money)

# **Step 6: Configure kubectl**

```bash
terraform output -raw configure_kubectl | bash
# Fetching cluster endpoint and auth data.
# kubeconfig entry generated for product-recsys-mlops-gke.
```

**What this does:**

1. **Gets the command from Terraform output**Â - Extracts the kubectl config command
2. **Runs it with bash**Â - Executes the command
3. **Downloads cluster credentials**Â - Gets authentication info
4. **UpdatesÂ `~/.kube/config`**Â - Saves cluster connection details

**Equivalent to running:**

```bash
gcloud container clusters get-credentials product-recsys-mlops-gke \
  --region us-east1 \
  --project product-recsys-mlops
```

**Output you'll see:**

```bash
Fetching cluster endpoint and auth data.
kubeconfig entry generated for product-recsys-mlops-gke.
```

**What it configures:**

```bash
# ~/.kube/config
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: <base64-cert>
    server: https://34.xxx.xxx.xxx  # Cluster endpoint
  name: gke_product-recsys-mlops_us-east1_product-recsys-mlops-gke
contexts:
- context:
    cluster: gke_product-recsys-mlops_us-east1_product-recsys-mlops-gke
    user: gke_product-recsys-mlops_us-east1_product-recsys-mlops-gke
  name: gke_product-recsys-mlops_us-east1_product-recsys-mlops-gke
current-context: gke_product-recsys-mlops_us-east1_product-recsys-mlops-gke
```

**Why needed:**

- AllowsÂ **`kubectl`**Â commands to connect to your cluster
- Required before you can deploy applications
- Sets this cluster as your default

# **Step 7: Verify Cluster**

```bash
kubectl get nodes
```

**What this does:**

- Connects to your GKE cluster
- Lists all nodes (worker machines)

**Output you'll see:**

```bash
No resources found
```

**Wait, no nodes?**Â This isÂ **NORMAL**Â for Autopilot!

**Why:**

- Autopilot creates nodesÂ **only when you deploy pods**
- No pods = no nodes = no cost! ğŸ’°
- Nodes appear automatically when needed

```bash
kubectl run test --image=nginx
kubectl get nodes
# Now you'll see nodes!
```

## **Step 8: Check Outputs**

```bash
terraform output
```

**What this does:**

- Shows all output values from your Terraform configuration
- Provides important information you'll need

**Output you'll see:**

```bash
artifact_registry_url = "us-east1-docker.pkg.dev/product-recsys-mlops/product-recsys-mlops-recsys"
configure_kubectl = "gcloud container clusters get-credentials product-recsys-mlops-gke --region us-east1 --project product-recsys-mlops"
docker_push_example = "docker push us-east1-docker.pkg.dev/product-recsys-mlops/product-recsys-mlops-recsys/recsys-api:latest"
gcs_bucket = "product-recsys-mlops-recsys-data"
gcs_bucket_url = "gs://product-recsys-mlops-recsys-data"
project_id = "product-recsys-mlops"
region = "us-east1"
```

**How to use these:**

```bash
# Get specific output
terraform output gcs_bucket
# Output: "product-recsys-mlops-recsys-data"

# Get raw value (no quotes)
terraform output -raw gcs_bucket
# Output: product-recsys-mlops-recsys-data

# Use in commands
gsutil ls gs://$(terraform output -raw gcs_bucket)
```

**Summary Timeline**

```bash
Step 1: Set project          â†’ 1 second
Step 2: Enable APIs          â†’ 30 seconds
Step 3: terraform init       â†’ 30 seconds
Step 4: terraform plan       â†’ 10 seconds
Step 5: terraform apply      â†’ 10-15 minutes â°
Step 6: configure kubectl    â†’ 5 seconds
Step 7: verify cluster       â†’ 2 seconds
Step 8: check outputs        â†’ 1 second

Total: ~15 minutes
```
